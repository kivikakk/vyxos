<!DOCTYPE html><html lang="en"><head>
    
    
    <meta charset="utf-8">
    
      <title>Time travel, raw - lottia notes</title>
      <meta property="og:title" content="Time travel, raw">
      <meta property="og:site_name" content="lottia notes">
      <meta property="og:description" content="Raw log from my notes re: &quot;Time travel&quot;.">
    
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="website">

    <meta name="author" content="Asherah Connor">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="stylesheet.css?v=1">
    <link rel="stylesheet" href="syntax.css">

    
      <link href="atom.xml" rel="alternate" title="lottia notes" type="application/atom+xml">
    
    <meta name="generator" content="Nanoc 4.12.16">
    <link rel="icon" type="image/png" href="lotte.png">
  </head>
  <body id="top">
    <div class="flex">
      <main>
        <h1>Time travel, raw</h1>
        
          <p>
            <span class="created-at">2024-07-06</span>
            
          </p>
        
        <section id="top">
<p>Raw log from my notes re: <a href="0008-time-travel.html">Time travel</a> follows.</p>
<h2>Sae</h2>
<p>RV32I with some RV32C/refactoring WIP from long ago. The WIP probably feels way too magic for me now, but we should take a look at it. Now uses Niar.</p>
</section>
<section id="todos">
<h3>TODOs <a href="#todos" aria-hidden="true" title="Permalink to section" class="anchor">üîó</a> <a href="#top" aria-hidden="true" title="Back to top" class="anchor">‚Ü©</a></h3>
<ul>
<li><a href="#decombing">Decombing</a></li>
<li>
<a href="#rv32c">RV32C</a> and associated refactor
<ul>
<li>Then add RV32E, RV64I?</li>
</ul>
</li>
<li>The entire test infra could be so much more robust.</li>
<li>M extension</li>
<li>A extension</li>
<li>‚ÄúZicsr‚Äù extension</li>
<li>BMC (WHAT DID THIS MEAN)</li>
<li>ili9341spi interface</li>
</ul>
</section>
<section id="decombing">
<h3>Decombing <a href="#decombing" aria-hidden="true" title="Permalink to section" class="anchor">üîó</a> <a href="#top" aria-hidden="true" title="Back to top" class="anchor">‚Ü©</a></h3>
<p>First priority is decombing the design to try to get the build time down. It‚Äôs currently redonkulous:</p>
<pre><code>[2024-07-03 13:05:24,917] niar: INFO: building sae for icebreaker
[2024-07-03 13:05:24,917] niar: DEBUG: starting elaboration
[2024-07-03 13:05:25,148] niar: DEBUG: elaboration finished in 0:00:00.230441
[2024-07-03 13:05:25,148] niar: DEBUG: 'sae.il': 425,987 bytes
[2024-07-03 13:05:25,148] niar: DEBUG: starting synthesis/pnr
[2024-07-03 13:05:25,148] niar: INFO: [run]   execute_build
[2024-07-03 13:08:12,179] niar: DEBUG: synthesis/pnr finished in 0:02:47.031564
[2024-07-03 13:08:12,207] niar: INFO: 
[2024-07-03 13:08:12,207] niar: INFO: === sae ===
[2024-07-03 13:08:12,207] niar: INFO: 
[2024-07-03 13:08:12,207] niar: INFO:    Number of wires:               2859
[2024-07-03 13:08:12,207] niar: INFO:    Number of wire bits:           9313
[2024-07-03 13:08:12,207] niar: INFO:    Number of public wires:        2859
[2024-07-03 13:08:12,208] niar: INFO:    Number of public wire bits:    9313
[2024-07-03 13:08:12,208] niar: INFO:    Number of ports:                  4
[2024-07-03 13:08:12,208] niar: INFO:    Number of port bits:              4
[2024-07-03 13:08:12,208] niar: INFO:    Number of memories:               0
[2024-07-03 13:08:12,208] niar: INFO:    Number of memory bits:            0
[2024-07-03 13:08:12,208] niar: INFO:    Number of processes:              0
[2024-07-03 13:08:12,208] niar: INFO:    Number of cells:               5732
[2024-07-03 13:08:12,208] niar: INFO:      $scopeinfo                     19
[2024-07-03 13:08:12,208] niar: INFO:      SB_CARRY                      452
[2024-07-03 13:08:12,208] niar: INFO:      SB_DFF                         79
[2024-07-03 13:08:12,208] niar: INFO:      SB_DFFE                        35
[2024-07-03 13:08:12,208] niar: INFO:      SB_DFFESR                    1380
[2024-07-03 13:08:12,208] niar: INFO:      SB_DFFSR                        8
[2024-07-03 13:08:12,208] niar: INFO:      SB_GB_IO                        1
[2024-07-03 13:08:12,208] niar: INFO:      SB_IO                           3
[2024-07-03 13:08:12,208] niar: INFO:      SB_LUT4                      3737
[2024-07-03 13:08:12,208] niar: INFO:      SB_RAM40_4K                    18
[2024-07-03 13:08:12,208] niar: INFO: 
[2024-07-03 13:08:12,208] niar: INFO: Device utilisation:
[2024-07-03 13:08:12,208] niar: INFO:            ICESTORM_LC:  5033/ 5280    95%
[2024-07-03 13:08:12,208] niar: INFO:           ICESTORM_RAM:    18/   30    60%
[2024-07-03 13:08:12,208] niar: INFO:                  SB_IO:     4/   96     4%
[2024-07-03 13:08:12,208] niar: INFO:                  SB_GB:     5/    8    62%
[2024-07-03 13:08:12,208] niar: INFO:           ICESTORM_PLL:     0/    1     0%
[2024-07-03 13:08:12,208] niar: INFO:            SB_WARMBOOT:     0/    1     0%
[2024-07-03 13:08:12,208] niar: INFO:           ICESTORM_DSP:     0/    8     0%
[2024-07-03 13:08:12,208] niar: INFO:         ICESTORM_HFOSC:     0/    1     0%
[2024-07-03 13:08:12,208] niar: INFO:         ICESTORM_LFOSC:     0/    1     0%
[2024-07-03 13:08:12,208] niar: INFO:                 SB_I2C:     0/    2     0%
[2024-07-03 13:08:12,208] niar: INFO:                 SB_SPI:     0/    2     0%
[2024-07-03 13:08:12,208] niar: INFO:                 IO_I3C:     0/    2     0%
[2024-07-03 13:08:12,208] niar: INFO:            SB_LEDDA_IP:     0/    1     0%
[2024-07-03 13:08:12,208] niar: INFO:            SB_RGBA_DRV:     0/    1     0%
[2024-07-03 13:08:12,208] niar: INFO:         ICESTORM_SPRAM:     0/    4     0%
[2024-07-03 13:08:12,208] niar: INFO: 
</code></pre>
<p>After moving the fault check out of <code>fetch.resolve</code>: 1:47, 4825 LCs.<br>
After using <code>.all()</code>: 1:44, 4802 LCs.<br>
After fixing our IL digest behaviour: priceless.</p>
<p>After splitting out just OP_IMM: 404k IL, 2:36, 5038 LCs. O_o<br>
I guess I need to split out the decode a little more? Or maybe it‚Äôs just a matter of decomposing more.</p>
<p>After replacing multiple <code>m.d.sync += self.write_xreg(v_i.rd, ...)</code> with one of those and a comb wire <code>out</code> for the value: <strong>404k IL, 1:35, 4851 LCs</strong>.</p>
<p>We‚Äôll split it out as much as possible at first, and then slowly reintegrate. We already do the register save in <code>fetch.init</code>, and now with some care after splitting out OP_IMM it‚Äôs a bit better again.</p>
<p>Need to remember that the toolchain does <em>much less deduplication than we assume</em>. Keep going on that, esp with insn decode.</p>
<p>Using <code>~insn[:16].bool()</code> instead of <code>== 0</code>: <strong>404k IL, 1:52, 4800 LCs</strong>.<br>
Using <code>wb_reg.any()</code> instead of <code>!= 0</code>: <strong>no change</strong>.</p>
<p>After splitting out LOAD: <strong>404k IL, 1:59, 4945 LCs</strong>. Uhm.<br>
After factoring the xreg fetch into common: <strong>402k IL, 1:46, 4972 LCs</strong>. Hmmmmmm.</p>
<p>After adding the read register: ran out of BELs. Welp. (6515 cells.)<br>
After changing the read register comb-&gt;sync: 6394 cells. Improved slightly.<br>
After splitting out OP: <strong>371k IL, 7166 cells</strong>. ‚Ä¶<br>
After refactoring OP with <code>out</code>: 7120 cells.<br>
After splitting out STORE: <strong>368k IL, 7134 cells</strong>.<br>
After splitting out BRANCH: <strong>343k IL, 6386 cells</strong>.<br>
After splitting out JALR: <strong>339k IL, 5599 cells and PNR is working again</strong>.<br>
After changing <code>jump(m, pc)</code>‚Äôs context manager return to <code>~_.bool()</code>: <strong>339k IL, 5602 cells</strong>. Uh, ok. Reverting that for now just ‚Äòcause maybe there‚Äôs a cross-over point (size of bv).</p>
<p>Using <code>any()</code> instead of <code>bool()</code> causes cell reduction? At 5587. <strong>339k IL, 1:04, 4774 LCs</strong>.<br>
OK, switching sync-&gt;comb on read regs bumps back up to 5664 (+77), and increases PNR time significantly (maybe because we‚Äôre close to cell count?). <strong>338k IL, 2:41, 4984 LCs (94%)</strong>.</p>
<p>Next step is to do the instruction decode in one place and then pass info to following stages.</p>
<p>Added <code>imm</code> and <code>funct3</code> to LOAD: <strong>342k IL, 1:06, 4905 LCs (92%)</strong>.<br>
Did the same to OP_IMM: <strong>342k IL, 0:58, 4886 LCs (92%)</strong>.<br>
Removed <code>v_sxi</code> wire and just used <code>imm[:12].as_signed()</code> in place: <strong>342k IL, 1:01, 4907 LCs (92%)</strong>.<br>
Did same deal to OP: <strong>343k IL, 1:01, 4806 LCs</strong>.<br>
Did same deal to STORE: <strong>344k IL, 1:16, 4816 LCs</strong>. !!!<br>
I forgot to only use the bottom 12 bits of <code>imm</code>. Fixed: <strong>344k IL, 1:09, 4910 LCs</strong>. What?<br>
Try doing the sign-extension in resolve: <strong>344k IL, 1:13, 4845 LCs</strong>.<br>
Do the thing for BRANCH: <strong>337k IL, 1:20, 4859 LCs</strong>.<br>
JALR too, that‚Äôs everything: <strong>337k IL, 1:13, 4812 LCs</strong>.<br>
Drop <code>v_sxi</code> and do the sign extension in resolve: <strong>336k IL, 1:15, 4825 LCs</strong>.<br>
Same for LOAD: <strong>336k IL, 1:17, 4774 LCs (90%)</strong>. Huh.</p>
<p>op.op_imm and op.op can be refactored.<br>
Hackily done: <strong>333k IL, 0:59, 4595 LCs</strong>. OK yeah, that helps!<br>
Done so that it actually works (still hack): <strong>333k IL, 1:05, 4633 LCs (87%)</strong>.</p>
<p>Put register file in memory now that it‚Äôs all separated out.<br>
(How much is it using, really? Half XCOUNT: <strong>288k IL, 0:19, 3340 LCs (63%)</strong>. OK, quite a bit.)</p>
<p>Pico fits in 750‚Äì1000. SERV fits in 198??????</p>
<p>Dumped it in a register file. Gave it two read ports so no existing code has to change, I think it‚Äôs just duplicated the memories but they‚Äôre so small it doesn‚Äôt matter. <strong>265k IL, 0:13, 2367 LCs (44%)</strong>.</p>
<p>Cleaned up our reg read and write logic: <strong>264k IL, 0:14, 2300 LCs (43%)</strong>.</p>
<p>TODOs remaining:</p>
<ul>
<li>
<input type="checkbox" checked="" disabled=""> Read all the accepted Amaranth RFCs.</li>
</ul>
<p>OK cool.</p>
<ul>
<li>
<input type="checkbox" checked="" disabled=""> Do a once-over and generally clean up the Hart.</li>
</ul>
<p>2291 LCs.<br>
2162 LCs after combing the MMU interface.<br>
2269 when I do it to the MMU write port. No point since we have to register a lot anyway. Back to 2162. Similarly it grows when I use comb to set <code>req_width</code> ‚Äî maybe because everything else in the FSM (back at this point) is sync, so they all switch together. Hrm.</p>
<p>Let‚Äôs try changing the write_xreg to comb. Basis: <code>8e3c38ca</code>, 2162 LCs. Hm, nah ‚Äî this can‚Äôt work. We assemble the components over multiple cycles fairly often (use <code>xwr_reg</code> to store <code>v_X.rd</code> etc.). What about read_xreg? The result is we <em>must</em> read the result when expected, since we‚Äôre no longer registering the address. I anticipate a growth in LCs (but faster reads).</p>
<p>2266 LCs, but haven‚Äôt removed the extra states yet so tests all fail.<br>
2303 LCs, necessitated an ALU refactor. So I don‚Äôt think there‚Äôs a benefit to this other than speed? Let‚Äôs see how many cycles CXXRTL gains.<br>
57508 after change, 57505 before. Well! The ALU split is something though, if I keep that it‚Äôs gonna be uglier anyway. How can I fix up?</p>
<p>Maybe we can tell the ALU where to read its inputs.</p>
<p>Adding a top-level ‚Äúdelay‚Äù that gates the whole FSM adds 100LCs. It‚Äôd be nice to have <em>one</em> wait state. Ah well.</p>
<p>2230 LCs after centralising the ALU. Splitting it into two stages gets us to ‚Ä¶ 2246? Oh. OK. Really didn‚Äôt expect that. Guess I won‚Äôt do that.</p>
<p>If we don‚Äôt have reg read <em>always on</em>, we can actually shuffle bits like <code>imm</code> <em>into</em> <code>xrd2_val</code>.</p>
<p>Up to 2303 on adding <code>xrd[12]_en</code>. ‚Ä¶ and hold the phone, <code>xrd2_val</code> is comb-driven. Nvm.<br>
It barely helps us anyway since we need to post-process for the ALU. Cancel that.</p>
<p>2202 after dropping the <code>m.If(funct7[5])</code> out of the <code>Else()</code> block ‚Äî <em>we</em> know they‚Äôre mutually exclusive, whereas it doesn‚Äôt.</p>
<p>On the contrary, 2189 after changing the <code>m.If(funct3 == ‚Ä¶ADDSUB): ‚Ä¶ / m.If(funct3 == ‚Ä¶.SR)</code> to if/elif: easier mux? It resembles a switch (which are probably optimised ‚Ä¶).</p>
<p>2202 after collapsing l.wait states. Cleaner. 2194 after fixing the default bug ‚Äî that‚Äôs 41%.</p>
<p>I would love to get a better idea <em>where</em> all these cells are being spent, but it‚Äôs pretty hard to say after optimisations.</p>
<ul>
<li>
<input type="checkbox" checked="" disabled=""> Consider the same for the MMU.
<ul>
<li>
<input type="checkbox" checked="" disabled=""> At minimum, use <code>amaranth.lib.stream</code> for its interface.</li>
</ul>
</li>
<li>
<input type="checkbox" checked="" disabled=""> Stop embedding the ‚Äúaddress bus‚Äù in the MMU along with the UART hook.</li>
<li>
<input type="checkbox" checked="" disabled=""> Clean up UART.</li>
<li>
<input type="checkbox" disabled=""> Move onto the big task.</li>
</ul>
<h4>Aside: ABTest</h4>
<p><strong>I feel like I want to make a little sandbox or something that makes evaluating the RTLIL diff between Amaranth expressions easier (optionally running it through <code>opt</code> or all the way through synthesis).</strong> Ideally it could even run in-situ, i.e.</p>
<pre><code class="language-python"><span class="k">with</span> <span class="n">ABTest</span><span class="p">.</span><span class="nc">A</span><span class="p">():</span>
    <span class="n">m</span><span class="p">.</span><span class="n">d</span><span class="p">.</span><span class="n">comb</span> <span class="o">+=</span> <span class="n">blah</span><span class="p">.</span><span class="nf">eq</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">16</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">with</span> <span class="n">ABTest</span><span class="p">.</span><span class="nc">B</span><span class="p">():</span>
    <span class="n">m</span><span class="p">.</span><span class="n">d</span><span class="p">.</span><span class="n">comb</span> <span class="o">+=</span> <span class="n">blah</span><span class="p">.</span><span class="nf">eq</span><span class="p">(</span><span class="o">~</span><span class="n">x</span><span class="p">[:</span><span class="mi">16</span><span class="p">].</span><span class="nf">bool</span><span class="p">())</span></code></pre>
<p>Or even:</p>
<pre><code class="language-python"><span class="n">m</span><span class="p">.</span><span class="n">d</span><span class="p">.</span><span class="n">comb</span> <span class="o">+=</span> <span class="n">blah</span><span class="p">.</span><span class="nf">eq</span><span class="p">(</span><span class="nc">ABTest</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">16</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">~</span><span class="n">x</span><span class="p">[:</span><span class="mi">16</span><span class="p">].</span><span class="nf">bool</span><span class="p">()))</span></code></pre>
<p>All such sites would be toggled individually (with others defaulting to ‚ÄúA‚Äù, no cartesian product) and then outputs presented for comparison.</p>
<p>Sae‚Äôs a bit slow to try this with right now.</p>
</section>
<section id="rv32c">
<h3>RV32C <a href="#rv32c" aria-hidden="true" title="Permalink to section" class="anchor">üîó</a> <a href="#top" aria-hidden="true" title="Back to top" class="anchor">‚Ü©</a></h3>
<p>This will take some re-understanding. We know the shape of the ISA(s) better now so we might be able to design something less Heppin Magic.</p>
<p>The cherry-picking went fairly straightforwardly, lots of conflicts but all easily resolved. Glad we did it in this order!</p>
<p>There‚Äôs <em>so</em> much magic in <code>isa.py</code> that I‚Äôm resolved to redesign this in a much more straightforward way.</p>
</section>
<section id="design">
<h4>Design <a href="#design" aria-hidden="true" title="Permalink to section" class="anchor">üîó</a> <a href="#top" aria-hidden="true" title="Back to top" class="anchor">‚Ü©</a></h4>
<p>Users of an ISA defined with this tool:</p>
<ul>
<li>assembler/disassembler
<ul>
<li>Opcodes and registers accessible via reflection, including support for defining shorthands (<code>J</code>, <code>LI</code>, etc.).</li>
<li>Need to be able to go the other way, too.</li>
</ul>
</li>
<li>gateware
<ul>
<li>Clear and easy access to layouts and op constants.</li>
<li>Exposes metadata like ILEN/XLEN/XCOUNT for gateware to use.</li>
</ul>
</li>
<li>subclassing ISAs
<ul>
<li>Can be added to, removed from (e.g. RV32E reducing XCOUNT).</li>
<li>
</li></ul>
</li>
</ul>
<p>Goals:</p>
<ul>
<li>Much less magic.
<ul>
<li>Avoid metaclasses, avoid <code>__call__</code>.</li>
<li>Inspecting signatures is OK</li>
</ul>
</li>
<li>Just enough flexibility to express RV; other ISAs are currently a non-goal.
<ul>
<li>I <em>think</em> the current design encapsulates most of what we‚Äôll need here.</li>
</ul>
</li>
</ul>
<p>Notes on the existing design:</p>
<ul>
<li>Our current design doesn‚Äôt include an intermediate representation: <code>IThunk.__call__</code> winds up calling <code>shape.const().as_value().value</code>, building up args to pass to <code>const()</code>; there‚Äôs no real point of ‚Äúcalling it done‚Äù except for the first time it‚Äôs called.</li>
<li>Many layouts define immediates in groups of <code>imm0_4</code>, <code>imm5</code>, <code>imm6_11</code> kinds of things. Sometimes they also omit e.g. <code>imm0</code> (implied 0).</li>
<li>An <code>ISA</code> has a notion of a <code>Register</code>, which is a class defined in the return value of <code>ISA.RegisterSpecifier()</code> (!).
<ul>
<li>This uses <code>locals().update(members)</code> to define the members of an <code>IntEnum</code>, where registers is built up from a list of (name, alias0, ‚Ä¶, aliasn) tuples and a target size.</li>
<li>I think we‚Äôll still need something like this; it‚Äôs actually one of the least magic parts of this.</li>
</ul>
</li>
<li>All <code>ISA</code> members can define <code>_needs_named</code> and <code>_needs_finalised</code> attributes, processed in <code>ISAMeta.__new__</code>.
<ul>
<li>
<code>_needs_named</code> causes the assignment of <code>__name__</code> and <code>__fullname__</code> attributes, according to the name being assigned to.</li>
<li>
<code>_needs_finalised</code> calls <code>finalise</code> on the object with a reference to the <code>ISA</code>.</li>
<li>This lets members finish initialising themselves with an awareness of everything else defined in the <code>ISA</code>, including things defined (lexically) after them.</li>
<li>
<code>ILayout</code> is an empty baseclass with an <code>ILayoutMeta</code> metaclass.</li>
<li>
<code>ILayoutMeta.__new__</code> takes an optional argument <code>len</code> and assigns it to <code>cls.len</code> (where <code>cls</code> is the newly-created class).</li>
<li>If <code>layout</code> is specified, it marks the class as needing finalisation and checks that <code>cls.len</code> is in fact defined (either now, or in a superclass). Otherwise, it‚Äôs considered a layout base class.</li>
<li>
<code>ILayoutMeta.finalise</code>:
<ul>
<li>assembles the defining context dictionary by iterating the <code>ISA</code>‚Äôs MRO backwards for their <code>dir()</code>s, discounting names starting with underscore (<code>_</code>);
<ul>
<li>In other words, items in the <code>ISA</code> class and superclasses define the context for type-shape lookups.</li>
</ul>
</li>
<li>assembles the full type-shape dictionary by iterating the <code>ILayout</code> instance‚Äôs MRO backwards for annotations, starting from after <code>ISA.ILayout</code> itself;
<ul>
<li>In other words, annotations in class and its <code>ISA.ILayout</code> superclasses define the set of type-shapes available to <code>layout</code> items.</li>
<li>The context dictionary is used as <code>locals()</code> here.</li>
</ul>
</li>
<li>iterates over the <code>layout</code> tuple given by the subclass, constructing <code>cls._fields</code> by matching names to <code>ShapeCastable</code>s:
<ul>
<li>Members can be strings, in which case they refer to an annotation with a matching name.
<ul>
<li>If the exact match lookup is unsuccessful, the class‚Äôs <code>resolve()</code> function is called with some context (the remaining items in the layout, length of instruction remaining needing to be allocated to a field), which must succeed.</li>
</ul>
</li>
<li>Members can be <code>(name, shapecastable)</code>.</li>
</ul>
</li>
<li>initialises <code>cls.shape = StructLayout(cls._fields)</code>.</li>
<li>initialises <code>cls.values</code> and <code>cls.defaults</code> by calling <code>resolve_values</code> on the class‚Äôs existing (set by subclass definition) <code>values</code> and <code>defaults</code> members, if any.
<ul>
<li>These may not overlap.</li>
<li>
<code>ints</code> are <code>ints</code>, strings are treated as keys for the <code>ShapeCastable</code> for the corresponding field.
<ul>
<li>If item lookup fails, the <code>ShapeCastable</code>‚Äôs <code>__call__</code> is tried.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<code>ILayoutMeta.resolve</code> just raises an error. Is this really exposed on subclass instances? Surprising.</li>
<li>
<code>ILayoutMeta.xfrm</code> constructs the class and calls <code>xfrm</code> on it.
<ul>
<li>If <code>I</code> is an <code>ILayout</code> subclass, this just means <code>I.xfrm(‚Ä¶)</code> is the same as <code>I().xfrm()</code>, i.e. get an unrefined thunk and then transform it.
<ul>
<li>
<em>Digression:</em> for whatever reason we really like being able to use classes in these positions. It ‚Äúmust‚Äù be a class because it‚Äôs the result of defining something with <code>class Blah:</code>, which itself is needed because we often want to supply code, nested classes, etc. But why the insistence on calling the class itself? We don‚Äôt <em>ever</em> have class instances, and doesn‚Äôt that seem a bit strange?</li>
<li>Thinking forward, the class instances should be the intermediate representation, not a separate thunk class. You call <code>I()</code> or <code>I(a=b)</code>, you get a <code>&lt;myisa.MyISA.I object&gt;</code>, with the args hitting <code>I.__init__</code> like a regular human being.</li>
<li>This prevents our delightful (‚Ä¶) hack with <code>I(s)</code>. We can actually just call it <code>I.shape(s)</code>, which already exists because that‚Äôs what it does lol!!</li>
<li>I have some lingering concerns here around repeated work that currently happens in <code>finalise</code> etc. but let‚Äôs deoptimise now, and reoptimise after the design is sane.</li>
</ul>
</li>
</ul>
</li>
<li>
<code>ILayoutMeta.__call__</code> allows zero or one positional arguments, plus kwargs.
<ul>
<li>In the above example, this is <code>I(‚Ä¶)</code>.</li>
<li>Zero positionals asserts a layout is defined, and returns a new <code>IThunk(cls, kwargs)</code>.
<ul>
<li>In other words, <code>"I(a=b)"</code>. This denotes a partially refined instruction based on <code>I</code>.</li>
<li>Note that even <code>I()</code> is valid syntax, to get the same kind of thunk but not refining any part of it.</li>
</ul>
</li>
<li>One positional asserts a <code>Signal</code> argument is given and wraps it in the subclass‚Äôs <code>shape</code> (<code>cls.shape(s)</code>), so you can call <code>I(s)</code> to decode <code>s</code>.</li>
</ul>
</li>
<li>The <code>IThunk</code> is as close as we get to an ‚Äúintermediate representation‚Äù here.
<ul>
<li>Sets <code>_needs_named</code>, as it‚Äôs probably going to be assigned in an expression like <code>ADDI = I(funct3=I.IFunct.ADDI)</code>.</li>
<li>Stores the class it was constructed from and the <code>kwargs</code> we got.</li>
<li>
<code>xfrms</code> initialised to empty.</li>
<li>
<code>asm_args</code> is defined from <code>list(self.layout)</code>: it‚Äôs the list of arguments an assembly call need to provide. If your layout is <code>("opcode", "rd", "imm")</code>, we need an opcode, dest register and immediate.
<ul>
<li>
<code>opcode</code> is defined as type <code>Opcode</code> and <code>rd</code> as <code>Reg</code> in the defining context, and <code>imm</code> is handled in <code>IL.resolve</code> when it‚Äôs in the final position.</li>
<li>The <code>opcode</code> is refined by being specified in <code>kwargs</code>, leaving just <code>rd</code> and <code>imm</code> for the ‚Äúasm args‚Äù. So how does that happen?</li>
</ul>
</li>
<li>We iterate over all <code>values</code> and <code>defaults</code> in the IL class, and names in <code>kwargs</code>, removing from <code>asm_args</code> any specified there.</li>
<li>Next we iterate names in <code>kwargs</code>, asserting all specified are a part of the <code>layout</code>, and none are part of the IL class‚Äôs <code>values</code> (the distinction between <code>values</code> and <code>defaults</code> being whether they can be overridden in a thunk ctor or not).</li>
</ul>
</li>
<li>It has <code>clone()</code> and <code>partial(**kwargs)</code>; the former returns a new <code>IThunk</code> with copies of all settings (for declaration, immutable definition), the latter clones and updates <code>clone.kwargs</code> with given kwargs, removing those from <code>clone.asm_args</code> (further refinement of an <code>IThunk</code>).</li>
<li>It also has <code>xfrm(xfn, **kwarg_defaults)</code>, which appends a new transform to <code>clone.xfrms</code>, with some optional default kwargs.
<ul>
<li>Transforms are a function which are handed a set of kwargs, and return a dict to update kwargs given to the next one (or to the <code>ilcls.shape.const(‚Ä¶)</code> call at the end).</li>
<li>The kwargs start out as the thunk‚Äôs own <code>kwargs</code> mixed with any given to the <code>IThunk.__call__</code>, latter superseding the former.</li>
<li>The transform function‚Äôs signature is analysed: if you take a parameter <code>x</code>, the kwarg <code>x</code> is filled in (mandatory). If you specify <code>x=default</code>, then <code>kwarg_defaults</code> and finally <code>default</code> are used as fallbacks.
<ul>
<li>I wonder why <code>kwarg_defaults</code> is only allowed when no default is given. I guess they‚Äôre either really mandatory to specify, or possibly optional.</li>
<li>An example here is <code>shamt_xfrm(shamt, *, imm11_5=0)</code>. <code>SRAI</code> overrides this with <code>SRAI = I(funct3=I.IFunct.SRI).xfrm(I.shamt_xfrm, imm11_5=0b0100000)</code>; the others don‚Äôt override it at all.</li>
<li>In other words, <code>kwarg_defaults</code> is more like ‚Äúdefault overrides‚Äù. In either case I don‚Äôt imagine a user is actually setting one in a thunk, so maybe they should be treated that way.</li>
</ul>
</li>
<li>What‚Äôs unspecified here is a way for transforms to also transform <code>asm_args</code>, and that‚Äôs where I got up to with<code># clone.asm_args. ## RESUME XXX GOOD LUCK</code>.</li>
</ul>
</li>
<li>When an <code>IThunk</code> is called, we resolve the <code>args_for</code> the given kwargs.
<ul>
<li>We call the transform pipe with <code>self.kwargs | args</code>, i.e. those given while constructing the thunk mixed with those given while calling it.</li>
<li>The result of the pipe is asserted to match the layout and not override anything it‚Äôs not allowed to override.</li>
<li>The <code>ilcls.values</code>, <code>ilcls.defaults</code> (both already ‚Äòresolved‚Äô) and result of resolving the pipe‚Äôs output are all combined and become the args passed to <code>shape.const</code>.</li>
</ul>
</li>
<li>Note that transforms are called in the order given, so we must transform <code>asm_args</code> back-to-front, as inputs used by earlier transforms may be provided by later ones.
<ul>
<li>Actually this is just backwards unless we do yet-more-thunking/accumulating. Let‚Äôs reverse the order of how it should be called, so we can apply <code>asm_args</code> changes as <code>xfrm()</code> is called repeatedly. Actually call the transforms in reverse order.</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>

      </main>
      <div class="sidebar">
        <div class="sidebar-inner">
          <ul>
            <li class=""><a href="./">Home</a></li>
            <li><a rel="me" href="https://lottia.net">Author</a></li>
          </ul>

          
            <h2>Notes</h2>
            <ul>
              
                <li class=""><a href="0010-vyxos.html">VyxOS</a></li>
              
                <li class="active"><a href="0009-time-travel-raw.html">Time travel, raw</a></li>
              
                <li class=""><a href="0008-time-travel.html">Time travel</a></li>
              
                <li class=""><a href="0007-amaranth-to-chisel.html">Amaranth to Chisel</a></li>
              
                <li class=""><a href="0006-comrak-on-akkoma.html">Comrak on Akkoma</a></li>
              
                <li class=""><a href="0005-jambalam.html">Jambalam</a></li>
              
                <li class=""><a href="0004-happy-birthday.html">Happy birthday!</a></li>
              
                <li class=""><a href="0003-nix-revisited.html">Nix revisited</a></li>
              
                <li class=""><a href="0002-untangling-cycles.html">Untangling cycles</a></li>
              
                <li class=""><a href="0001-hdl-toolchain-source.html">Installing an HDL toolchain from source</a></li>
              
            </ul>
          

          
        </div>

        
          <div class="toc">
            <div class="toc-inner">
              <h2>Table of contents</h2>

              <ul>
                <li>
                  <a href="#top">Top</a>
                  
                    
                      
                        </li><li>
                      
                      <a href="#todos">TODOs</a>
                    
                  
                    
                      
                        </li><li>
                      
                      <a href="#decombing">Decombing</a>
                    
                  
                    
                      
                        </li><li>
                      
                      <a href="#rv32c">RV32C</a>
                    
                  
                    
                      <ul><li>
                    
                  
                    
                      
                      <a href="#design">Design</a>
                    
                  
                    
                      </li></ul>
                    
                  
                </li>
              </ul>
            </div>
          </div>
        
      </div>
    </div>
    <footer>
      <p>
        Licensed under the <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a>
        by its author.
      </p>
    </footer>
    <script src="toc-highlight.js"></script>
  

</body></html>